{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Many thanks for the book [The Hundred-Page Machine Learning Book](http://themlbook.com/) by [Andriy Burkov](https://www.linkedin.com/in/andriyburkov/), so please [check this out](http://themlbook.com/wiki/doku.php?id=start)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# !pip install -U scikit-learn==1.2.2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip show scikit-learn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from prediction_strength import get_prediction_strength\n",
    "from tqdm.notebook import tqdm\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Read data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"data/WQ-R.csv\",sep=\";\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"N rows - {df.shape[0]}\\nN cols - {df.shape[1]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = df[\"quality\"].astype(int)\n",
    "X = df.drop([\"quality\"], axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(y.value_counts().sort_index()/y.shape[0]*100).round(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are 3 big clusters based on quality's values (4,5,6) and others (3,4,8) values are relatively poor presented"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = X.columns\n",
    "print(f\"Features:\\n{X.columns.to_list()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. KMeans\n",
    "Dividing the data set into clusters with a random initialization and outputting the coordinates of the centers of the clusters.\n",
    "The optimal number of clusters can be determined based on the initial data set in three different ways:\n",
    "    1) elbow method;\n",
    "    2) average silhouette method;\n",
    "    3) prediction strength method (see section 9.2.3 Determining the Number of Clusters of the book Andriy Burkov. The Hundred-Page Machine Learning Book).\n",
    "Compare the obtained results and explain which method gave the best result and why (in your opinion)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I have found [this article](https://towardsdatascience.com/silhouette-method-better-than-elbow-method-to-find-optimal-clusters-378d62ff6891) extremely useful.\n",
    "The article stands out with its easy readability and its effective simplification of complex ideas using relevant examples.\n",
    "Its clear descriptions and the inclusion of useful functions for cluster analysis make it a highly valuable resource\n",
    "<img src=\"img/Silhouette Method.png\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is [another article](https://uc-r.github.io/kmeans_clustering), which is great source for studying theory enough to get intuition behind K-means cluster analysis.\n",
    "Especially, Determining Optimal Clusters topic is written good."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1) Elbow method"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**KElbowVisualizer**\n",
    "By default, the scoring parameter metric is set to distortion,\n",
    "which computes the sum of squared distances from each point to its assigned center.\n",
    "\n",
    "However, two other metrics can also be used with the KElbowVisualizer â€“ silhouette and calinski_harabasz.\n",
    "The silhouette score calculates the mean Silhouette Coefficient of all samples,\n",
    "while the calinski_harabasz score computes the ratio of dispersion between and within clusters.\n",
    "https://www.scikit-yb.org/en/latest/api/cluster/elbow.html?highlight=metric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Instantiate the clustering model and visualizer\n",
    "model = KMeans(init='random', random_state=42)\n",
    "visualizer = KElbowVisualizer(\n",
    "    model, k=(2,14), metric='distortion', timings=False\n",
    ")\n",
    "visualizer.fit(X)        # Fit the data to the visualizer\n",
    "visualizer.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot Distortion Score Elbow for KMeans Clustering using fitted KMeans.inertia_ attribute."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "avg_distance = []\n",
    "range_n_clusters = range(2, 15)\n",
    "for n_clusters in range_n_clusters:\n",
    "    clusterer = KMeans(n_clusters=n_clusters, init='random', random_state=42).fit(X)\n",
    "    print(f'Center`s coordinates for n_clusters {n_clusters}:\\n{pd.DataFrame(clusterer.cluster_centers_).to_string()}\\n')\n",
    "    avg_distance.append(clusterer.inertia_)\n",
    "\n",
    "style.use(\"fivethirtyeight\")\n",
    "plt.plot(range_n_clusters, avg_distance)\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the above plot, there is a sharp fall of average distance at k=3, 4 and 5. Here comes a confusion to pick the best value of k."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2) Average silhouette method"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "silhouette_avg_n_clusters = []\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, init='random', random_state=42)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    print(f'Center`s coordinates for n_clusters {n_clusters}:\\n{pd.DataFrame(clusterer.cluster_centers_).to_string()}\\n')\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    # print(\"For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    silhouette_avg_n_clusters.append(silhouette_avg)\n",
    "\n",
    "plt.plot(range_n_clusters, silhouette_avg_n_clusters)\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"The average silhouette score\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = KMeans(init='random', random_state=42)\n",
    "visualizer = KElbowVisualizer(\n",
    "    model, k=(2,14), metric='silhouette', timings=False\n",
    ")\n",
    "visualizer.fit(X)        # Fit the data to the visualizer\n",
    "visualizer.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The silhouette plot shows that the n_cluster value of more than 6 is a bad pick.\n",
    "So, let`s investigate deeper n_cluster values 2-6 by plotting the silhouette scores for each sample in cluster."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "silhouette_avg_n_clusters = []\n",
    "range_n_clusters = range(2, 7)\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Create a subplot with 1 row and 1 column\n",
    "    fig, (ax1) = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(10, 5)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, init='random', random_state=42)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    silhouette_avg_n_clusters.append(silhouette_avg)\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    # ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "style.use(\"fivethirtyeight\")\n",
    "plt.plot(range_n_clusters, silhouette_avg_n_clusters)\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"silhouette score\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The silhouette plots show that all the points in the clusters are below-average silhouette scores.\n",
    "I prefer to choose between 3 and 4, considering the points in the cluster with cluster_label=1,2 are both higher than 0.6.\n",
    "Talking in machine learning terms, n_clusters=2 is under-fitting and n_clusters=5 is over-fitting."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3) Prediction strength method"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I have found [this article](https://towardsdatascience.com/silhouette-method-better-than-elbow-method-to-find-optimal-clusters-378d62ff6891) extremely useful.\n",
    "Especially, Prediction Strength topic with provided python f-ns for calculation.\n",
    "<img src=\"img/Prediction Strength.png\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2, shuffle=True, stratify=y, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# running the clustering\n",
    "strengths = []\n",
    "range_n_clusters = range(2, 10)\n",
    "\n",
    "for k in tqdm(range_n_clusters):\n",
    "    model_train = KMeans(n_clusters=k, init='random', random_state=42).fit(X_train)\n",
    "    model_test = KMeans(n_clusters=k, init='random', random_state=42).fit(X_test)\n",
    "\n",
    "    print(f'Train, center`s coordinates for n_clusters {k}:\\n{pd.DataFrame(model_train.cluster_centers_).to_string()}\\n')\n",
    "    print(f'Test, center`s coordinates for n_clusters {k}:\\n{pd.DataFrame(model_test.cluster_centers_).to_string()}\\n\\n\\n')\n",
    "\n",
    "    pred_str = get_prediction_strength(k, model_train.cluster_centers_, X_test, model_test.labels_)\n",
    "    strengths.append(pred_str)\n",
    "\n",
    "# plotting\n",
    "_, ax = plt.subplots()\n",
    "ax.plot(range_n_clusters, strengths, '-o', color='black')\n",
    "ax.axhline(y=0.8, c='red')\n",
    "ax.set(title='Determining the optimal number of clusters',\n",
    "       xlabel='number of clusters',\n",
    "       ylabel='prediction strength')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the recommended cluster size is 2.\n",
    "Considering between 3 and 4, we should go for 4."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Summary\n",
    "We got optimal n_clucters value in range 3-6, using the elbow method.\n",
    "Then, the average silhouette method showed the best metric at n_clucters=2, but we chose 3-4 range.\n",
    "The last method showed that the only n_clucters=2 over-performed prediction strength threshold 0.8.\n",
    "The second-best result was devoted to n_clucters=4."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. KMeans++\n",
    "Run multiple times for the previously selected number of clusters k-means clustering, using k-means++ method for initial initialization.\n",
    "Choose the best clustering option using chosen quantitative criterion."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To get familiar with K-means++, I found useful this article [k-means++: The Advantages of Careful Seeding](https://theory.stanford.edu/~sergei/papers/kMeansPP-soda.pdf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1) Elbow method"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "avg_distance = []\n",
    "range_n_clusters = range(2, 15)\n",
    "for n_clusters in tqdm(range_n_clusters):\n",
    "    clusterer = KMeans(n_clusters=n_clusters, init='k-means++', n_init=100, random_state=42).fit(X)\n",
    "    print(f'Center`s coordinates for n_clusters {n_clusters}:\\n{pd.DataFrame(clusterer.cluster_centers_).to_string()}\\n')\n",
    "\n",
    "    avg_distance.append(clusterer.inertia_)\n",
    "\n",
    "style.use(\"fivethirtyeight\")\n",
    "plt.plot(range_n_clusters, avg_distance)\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running 100 times the k-means algorithm with different centroid seeds definitely made difference.\n",
    "The curve became smoother. It is very interesting, so let`s take a look at the sklearn documentation:\n",
    "\n",
    "*\"The final results is the best output of n_init consecutive runs in terms of inertia.\"*\n",
    "\n",
    "There are relatively a sharp falls of average distance at k=3 and 4."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2) Average silhouette method"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "silhouette_avg_n_clusters = []\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, init='k-means++', n_init=100, random_state=42)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    print(f'Center`s coordinates for n_clusters {n_clusters}:\\n{pd.DataFrame(clusterer.cluster_centers_).to_string()}\\n')\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    # print(\"For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    silhouette_avg_n_clusters.append(silhouette_avg)\n",
    "\n",
    "plt.plot(range_n_clusters, silhouette_avg_n_clusters)\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"The average silhouette score\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The silhouette plot shows that the n_cluster value of more than 5 is a bad pick,\n",
    "as the average silhouette score is the same or lower than at n_cluster = 5.\n",
    "So, let`s investigate deeper n_cluster values 2-5 by plotting the silhouette scores for each sample in cluster."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "silhouette_avg_n_clusters = []\n",
    "range_n_clusters = range(2, 6)\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Create a subplot with 1 row and 1 column\n",
    "    fig, (ax1) = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(10, 5)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, init='k-means++', n_init=100, random_state=42)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    silhouette_avg_n_clusters.append(silhouette_avg)\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    # ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "style.use(\"fivethirtyeight\")\n",
    "plt.plot(range_n_clusters, silhouette_avg_n_clusters)\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"silhouette score\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let`s compare results of init mode 'random' and 'kmeans++':\n",
    "- For n_clusters = 2: The average silhouette_score is : 0.6034 vs 0.6034\n",
    "- For n_clusters = 3 The average silhouette_score is : 0.5197 vs 0.5209\n",
    "- For n_clusters = 4 The average silhouette_score is : 0.4897 vs 0.4861\n",
    "- For n_clusters = 5 The average silhouette_score is : 0.4406 vs 0.4474"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We definitely can find the difference.\n",
    "At n_clusters=5, we can find 2nd cluster had more than 0.6 silhouette_score at init mode 'random'.\n",
    "Which seems to be misleading, because we have got silhouette_score value less than 0.6  using init mode 'kmeans++'.\n",
    "\n",
    "Overall, I still prefer to choose between 3 and 4."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3) Prediction strength method"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# running the clustering\n",
    "strengths = []\n",
    "range_n_clusters = range(2, 7)\n",
    "\n",
    "for k in tqdm(range_n_clusters):\n",
    "    model_train = KMeans(n_clusters=k, init='k-means++', n_init=100, random_state=42).fit(X_train)\n",
    "    model_test = KMeans(n_clusters=k, init='k-means++', n_init=100, random_state=42).fit(X_test)\n",
    "\n",
    "    print(f'Train, center`s coordinates for n_clusters {k}:\\n{pd.DataFrame(model_train.cluster_centers_).to_string()}\\n')\n",
    "    print(f'Test, center`s coordinates for n_clusters {k}:\\n{pd.DataFrame(model_test.cluster_centers_).to_string()}\\n\\n\\n')\n",
    "\n",
    "    pred_str = get_prediction_strength(k, model_train.cluster_centers_, X_test, model_test.labels_)\n",
    "    strengths.append(pred_str)\n",
    "\n",
    "# plotting\n",
    "_, ax = plt.subplots()\n",
    "ax.plot(range_n_clusters, strengths, '-o', color='black')\n",
    "ax.axhline(y=0.8, c='red')\n",
    "ax.set(title='Determining the optimal number of clusters',\n",
    "       xlabel='number of clusters',\n",
    "       ylabel='prediction strength')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have got same results, the recommended cluster size is 2, but I prefer 4."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Summary\n",
    "The forms of curves become smoother using \"kmeans++\", which we have got using \"Elbow method\" and \"Average silhouette method\".\n",
    "The \"Prediction strength\" plot looks the same, but the overall power became lower.\n",
    "Considering findings, the given results of both approaches (init mode \"random\" and \"kmeans++\") seem to be slightly different, but pretty the same.\n",
    "I found the contradiction in n_cluster=3, between using \"Elbow method\", \"Average silhouette method\" and \"Prediction strength\".\n",
    "So, probably, in case I would stop my analysis at \"Elbow method\" and \"Average silhouette method\", I would prefer n_cluster=2 or 3, more than 4.\n",
    "But, \"Prediction strength\" method became \"game changer\", that leads us to an idea that there are two options n_cluster=2 or 4."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. AgglomerativeClustering\n",
    "Using the AgglomerativeClustering function of the scikit-learn library, divide the data set into clusters.\n",
    "Number of clusters choose the same as in the previous method.\n",
    "Take out coordinates of cluster centers."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1) Elbow method"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Instantiate the clustering model and visualizer\n",
    "model = AgglomerativeClustering()\n",
    "visualizer = KElbowVisualizer(\n",
    "    model, k=(2,14), metric='distortion', timings=False\n",
    ")\n",
    "visualizer.fit(X)        # Fit the data to the visualizer\n",
    "visualizer.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the above plot, the sharpest fall of average distance was spotted at k=5.\n",
    "The plot is very similar to the previous one (3.1)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2) Average silhouette method"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = AgglomerativeClustering()\n",
    "visualizer = KElbowVisualizer(\n",
    "    model, k=(2,14), metric='silhouette', timings=False\n",
    ")\n",
    "visualizer.fit(X)        # Fit the data to the visualizer\n",
    "visualizer.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The silhouette plot shows that the n_cluster value of more than 4 is a bad pick.\n",
    "The next point, at n_cluster=5, trend is broken.\n",
    "The plot shows that n_cluster=2 is best option, but we can try n_cluster=3 and 4."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.3) Prediction strength method"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# running the clustering\n",
    "strengths = []\n",
    "range_n_clusters = range(2, 10)\n",
    "\n",
    "for k in tqdm(range_n_clusters):\n",
    "    model_train = AgglomerativeClustering(n_clusters=k).fit(X_train)\n",
    "    model_test = AgglomerativeClustering(n_clusters=k).fit(X_test)\n",
    "\n",
    "    # Computing cluster centers, which are simply the mean of all the rows in that cluster\n",
    "    # many thanks to https://tushar-osc.medium.com/agglomerativeclustering-with-cluster-centers-e5d409c724d1\n",
    "    train_cluster_centers = []\n",
    "\n",
    "    for j_cluster in range(model_train.n_clusters):\n",
    "        j_cluster_center = X_train[model_train.labels_==j_cluster,:].mean(axis=0)\n",
    "        train_cluster_centers.append(j_cluster_center)\n",
    "\n",
    "    print(f'Center`s coordinates for n_clusters {k}:\\n{pd.DataFrame(train_cluster_centers).to_string()}\\n\\n')\n",
    "\n",
    "    pred_str = get_prediction_strength(k, train_cluster_centers, X_test, model_test.labels_)\n",
    "    strengths.append(pred_str)\n",
    "\n",
    "# plotting\n",
    "_, ax = plt.subplots()\n",
    "ax.plot(range_n_clusters, strengths, '-o', color='black')\n",
    "ax.axhline(y=0.8, c='red')\n",
    "ax.set(title='Determining the optimal number of clusters',\n",
    "       xlabel='number of clusters',\n",
    "       ylabel='prediction strength')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the recommended cluster size is 2.\n",
    "Surprisingly, the next top \"prediction strength\" value is at n_clusters=5."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Summary\n",
    "We got optimal n_clucters=5, using the elbow method.\n",
    "Then, the average silhouette method showed the best metric at n_clucters=2, but we chose 3-4 range.\n",
    "The last method showed that the only n_clucters=2 over-performed prediction strength threshold 0.8.\n",
    "The second-best result was devoted to n_clucters=5.\n",
    "\n",
    "It is surprising, that at n_cluster=5, \"the average silhouette method\" plot`s trend is broken,\n",
    "but the elbow method suggests same value for n_clucters, and \"prediction strength\" too (in case we want more than 2 clusters)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. K-means vs AgglomerativeClustering comparison"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Previously, we have already compared K-means and K-means++ approaches.\n",
    "Let`s compare K-means++ and AgglomerativeClustering.\n",
    "The last conclusion at K-means++ section was that the best two values of n_cluster are 2 and 4.\n",
    "AgglomerativeClustering shows the same top 1 value, but the second is n_cluster=5.\n",
    "\n",
    "To summarize, the difference between K-means++ and AgglomerativeClustering doesn't seem to be dramatic in terms of optimal n_clusters values.\n",
    "\n",
    "Meanwhile, we haven't covered at this moment the analysis of differences in centroids.\n",
    "Another part of clustering analysis is 2D scatter plots using dimensionality reduction technics.\n",
    "These and other steps could be done within further investigation to compare the clusters themselves more precisely."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
