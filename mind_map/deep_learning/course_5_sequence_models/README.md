# Sequence Models

This repository contains a collection of practical Deep Learning projects, focusing on Recurrent Neural Networks, Language Modeling, Word Vector operations, Neural Machine Translation, and Transformer Networks.

## Table of Contents
- [Building your Recurrent Neural Network - Step by Step](#building-your-recurrent-neural-network---step-by-step)
- [Dinosaur Island-Character-Level Language Modeling](#dinosaur-island-character-level-language-modeling)
- [Jazz Improvisation with LSTM](#jazz-improvisation-with-lstm)
- [Operations on Word Vectors - Debiasing](#operations-on-word-vectors---debiasing)
- [Emojify](#emojify)
- [Neural Machine Translation](#neural-machine-translation)
- [Trigger Word Detection](#trigger-word-detection)
- [Transformers Architecture with TensorFlow](#transformers-architecture-with-tensorflow)
- [Transformer Pre-processing](#transformer-pre-processing)
- [Transformer Network Application: Named-Entity Recognition](#transformer-network-application-named-entity-recognition)
- [Transformer Network Application: Question Answering](#transformer-network-application-question-answering)
- [Transformers using Trax Library](#transformers-using-trax-library)

## [Building your Recurrent Neural Network - Step by Step](W1A1/Building_a_Recurrent_Neural_Network_Step_by_Step.ipynb)

In this project, we will walk through the process of building a Recurrent Neural Network (RNN) from scratch.

## [Dinosaur Island-Character-Level Language Modeling](W1A2/Dinosaurus_Island_Character_level_language_model.ipynb)

This project focuses on character-level language modeling using a dataset from Dinosaur Island.

## [Jazz Improvisation with LSTM](W1A3/Improvise_a_Jazz_Solo_with_an_LSTM_Network_v4.ipynb)

In this project, we explore the application of Long Short-Term Memory (LSTM) networks in generating Jazz music improvisation.

## [Operations on Word Vectors - Debiasing](W2A1/Operations_on_word_vectors_v2a.ipynb)

Here, we work on operations on word vectors and focus specifically on techniques for debiasing these word vectors.

## [Emojify](W2A2/Emoji_v3a.ipynb)

In the Emojify project, we implement a model that inputs a sentence and finds the most appropriate emoji to be used with this sentence.

## [Neural Machine Translation](W3A1/Neural_machine_translation_with_attention_v4a.ipynb)

This project involves the implementation of a Neural Machine Translation (NMT) system to convert input text from one language to another.

## [Trigger Word Detection](W3A2/Trigger_word_detection_v2a.ipynb)

In the Trigger Word Detection project, we create a system to train a model to recognize a specific word or phrase in a given input audio clip.

## [Transformers Architecture with TensorFlow](W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb)

This project deals with the implementation of Transformer architecture using TensorFlow.

## [Transformer Pre-processing](W4A4_UGL_POS/Embedding_plus_Positional_encoding.ipynb)

In this project, we delve into various pre-processing techniques used before feeding the data into a Transformer network.

## [Transformer Network Application: Named-Entity Recognition](W4A2_UGL/Transformer_application_Named_Entity_Recognition.ipynb)

Here, we apply the Transformer network to Named-Entity Recognition (NER) tasks.

## [Transformer Network Application: Question Answering](W4A3_UGL/QA_dataset.ipynb)

In this project, we utilize Transformer networks to build a model for question answering tasks.


## Contribution

Contributions to this repository are welcomed. Please make a pull request.

## License

All materials are released under the [MIT License](LICENSE).
